{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64310a86",
   "metadata": {},
   "source": [
    "# Implementation of Utility functions required for Protein Structure Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c77dba",
   "metadata": {},
   "source": [
    "## Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "703246a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import PeptideBuilder\n",
    "import Bio.PDB\n",
    "from Bio.Data.IUPACData import protein_letters_1to3\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd1f06",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b439db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DIMENSIONS = 3\n",
    "NUM_DIHEDRALS = 3\n",
    "BOND_LENGTHS = torch.tensor([145.801, 152.326, 132.868], dtype=torch.float32)\n",
    "BOND_ANGLES = torch.tensor([2.124, 1.941, 2.028], dtype=torch.float32)\n",
    "PNERF_INIT_MATRIX = [torch.tensor([-torch.sqrt(torch.tensor([1.0 / 2.0])),\n",
    "                                   torch.sqrt(torch.tensor([3.0 / 2.0])), 0]),\n",
    "                     torch.tensor([-torch.sqrt(torch.tensor([2.0])), 0, 0]),\n",
    "                     torch.tensor([0, 0, 0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018eca32",
   "metadata": {},
   "source": [
    "### Defining Amino Acid Dictionary and PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee56cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_ID_DICT = {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9,\n",
    "              'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17,\n",
    "              'V': 18, 'W': 19, 'Y': 20}\n",
    "\n",
    "PI_TENSOR = torch.tensor([3.141592])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2837ef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1416])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI_TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa10e1",
   "metadata": {},
   "source": [
    "### Function to create a PyTorch DataLoader for Loading the Protein data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04f1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contruct_dataloader_from_disk(filename, minibatch_size):\n",
    "    return torch.utils.data.DataLoader(H5PytorchDataset(filename),\n",
    "                                       batch_size=minibatch_size,\n",
    "                                       shuffle=True,\n",
    "                                       collate_fn=merge_samples_to_minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a4ae7",
   "metadata": {},
   "source": [
    "### Function to access the Protein database as a Map Type Dataset for the DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1a43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5PytorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filename):\n",
    "        super(H5PytorchDataset, self).__init__()\n",
    "\n",
    "        self.h5pyfile = h5py.File(filename, 'r')\n",
    "        self.num_proteins, self.max_sequence_len = self.h5pyfile['primary'].shape\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        mask = torch.Tensor(self.h5pyfile['mask'][index, :]).type(dtype=torch.bool)\n",
    "        prim = torch.masked_select(\n",
    "            torch.Tensor(self.h5pyfile['primary'][index, :]).type(dtype=torch.int),\n",
    "            mask)\n",
    "        tertiary = torch.Tensor(self.h5pyfile['tertiary'][index][:int(mask.sum())])\n",
    "        return prim, tertiary, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82652f6b",
   "metadata": {},
   "source": [
    "### Function to merge the Protein Samples into a Mini Batch for Mini-Batch Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478be4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_samples_to_minibatch(samples):\n",
    "    samples_list = []\n",
    "    for sample in samples:\n",
    "        samples_list.append(sample)\n",
    "    # sort according to length of aa sequence\n",
    "    samples_list.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    return zip(*samples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6f64e",
   "metadata": {},
   "source": [
    "### Function to set the Experiment Id for each of the Mini-Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b0fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_experiment_id(data_set_identifier, learning_rate, minibatch_size):\n",
    "    output_string = datetime.now().strftime('%Y-%m-%d_%H_%M_%S')\n",
    "    output_string += \"-\" + str(os.getpid())\n",
    "    output_string += \"-\" + data_set_identifier\n",
    "    output_string += \"-LR\" + str(learning_rate).replace(\".\", \"_\")\n",
    "    output_string += \"-MB\" + str(minibatch_size)\n",
    "    globals().__setitem__(\"experiment_id\", output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c89fa",
   "metadata": {},
   "source": [
    "### Function to get the Experiment Id of a Mini Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097948dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_id():\n",
    "    return globals().get(\"experiment_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621f572",
   "metadata": {},
   "source": [
    "### Function to save the model into an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a755c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_to_disk(model):\n",
    "    path = \"output/models/\" + globals().get(\"experiment_id\") + \".model\"\n",
    "    torch.save(model, path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b2db8",
   "metadata": {},
   "source": [
    "### Function to write the prediction data into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c9c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_prediction_data_to_disk(prediction_data):\n",
    "    filepath = \"output/predictions/\" + globals().get(\"experiment_id\") + \".txt\"\n",
    "    output_file = open(filepath, 'w')\n",
    "    output_file.write(prediction_data)\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e114a",
   "metadata": {},
   "source": [
    "### Function to write the summary of the experiment into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d1a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result_summary(accuracy):\n",
    "    output_string = globals().get(\"experiment_id\") + \": \" + str(accuracy) + \"\\n\"\n",
    "    with open(\"output/result_summary.txt\", \"a+\") as output_file:\n",
    "        output_file.write(output_string)\n",
    "        output_file.flush()\n",
    "    print(output_string, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf7f44",
   "metadata": {},
   "source": [
    "### Function to convert protein id into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2591804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_id_to_str(protein_id_list):\n",
    "    _aa_dict_inverse = {v: k for k, v in AA_ID_DICT.items()}\n",
    "    aa_list = []\n",
    "    for protein_id in protein_id_list:\n",
    "        aa_symbol = _aa_dict_inverse[protein_id.item()]\n",
    "        aa_list.append(aa_symbol)\n",
    "    return aa_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf5f61",
   "metadata": {},
   "source": [
    "### Function to write arguments into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ee9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out(*args, end='\\n'):\n",
    "    output_string = datetime.now().strftime('%Y-%m-%d %H:%M:%S') \\\n",
    "                    + \": \" + str.join(\" \", [str(a) for a in args]) + end\n",
    "    if globals().get(\"experiment_id\") is not None:\n",
    "        with open(\"output/\" + globals().get(\"experiment_id\") + \".txt\", \"a+\") as output_file:\n",
    "            output_file.write(output_string)\n",
    "            output_file.flush()\n",
    "    print(output_string, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf8871",
   "metadata": {},
   "source": [
    "### Function to draw the train_loss_values for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cab9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(fig, plt, validation_dataset_size, sample_num, train_loss_values,\n",
    "              validation_loss_values):\n",
    "    def draw_with_vars():\n",
    "        ax = fig.gca()\n",
    "        ax2 = ax.twinx()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Training progress (\" + str(validation_dataset_size)\n",
    "                  + \" samples in validation set)\")\n",
    "        train_loss_plot, = ax.plot(sample_num, train_loss_values)\n",
    "        ax.set_ylabel('Train Negative log likelihood')\n",
    "        ax.yaxis.labelpad = 0\n",
    "        validation_loss_plot, = ax2.plot(sample_num, validation_loss_values, color='black')\n",
    "        ax2.set_ylabel('Validation loss')\n",
    "        ax2.set_ylim(bottom=0)\n",
    "        plt.legend([train_loss_plot, validation_loss_plot],\n",
    "                   ['Train loss on last batch', 'Validation loss'])\n",
    "        ax.set_xlabel('Minibatches processed (=network updates)', color='black')\n",
    "\n",
    "    return draw_with_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be3f68",
   "metadata": {},
   "source": [
    "### Function to draw the Ramachandran Plot for protein structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfea005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ramachandran_plot(fig, plt, phi, psi):\n",
    "    def draw_with_vars():\n",
    "        ax = fig.gca()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Ramachandran plot\")\n",
    "        train_loss_plot, = ax.plot(phi, psi)\n",
    "        ax.set_ylabel('Psi')\n",
    "        ax.yaxis.labelpad = 0\n",
    "        plt.legend([train_loss_plot],\n",
    "                   ['Phi psi'])\n",
    "        ax.set_xlabel('Phi', color='black')\n",
    "\n",
    "    return draw_with_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8b540",
   "metadata": {},
   "source": [
    "### Function to calculate the dihedral angles of the mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8a9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dihedral_angles_over_minibatch(atomic_coords_padded, batch_sizes, use_gpu):\n",
    "    angles = []\n",
    "    batch_sizes = torch.LongTensor(batch_sizes)\n",
    "    atomic_coords = atomic_coords_padded.transpose(0, 1)\n",
    "\n",
    "    for idx, coordinate in enumerate(atomic_coords.split(1, dim=0)):\n",
    "        angles_from_coords = torch.index_select(\n",
    "            coordinate.squeeze(0),\n",
    "            0,\n",
    "            torch.arange(int(batch_sizes[idx].item()))\n",
    "        )\n",
    "        angles.append(calculate_dihedral_angles(angles_from_coords, use_gpu))\n",
    "\n",
    "    return torch.nn.utils.rnn.pad_sequence(angles), batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c47ea",
   "metadata": {},
   "source": [
    "### Function to calculate the dihedral angles from atomic coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f510fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dihedral_angles(atomic_coords, use_gpu):\n",
    "    atomic_coords = atomic_coords.contiguous().view(-1, 3)\n",
    "\n",
    "    zero_tensor = torch.zeros(1)\n",
    "    if use_gpu:\n",
    "        zero_tensor = zero_tensor.cuda()\n",
    "\n",
    "\n",
    "\n",
    "    angles = torch.cat((zero_tensor,\n",
    "                        zero_tensor,\n",
    "                        compute_dihedral_list(atomic_coords),\n",
    "                        zero_tensor)).view(-1, 3)\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df658789",
   "metadata": {},
   "source": [
    "### Function to calculate the cross products of two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27067287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross(tensor_a, tensor_b, dim):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    x = torch.zeros(1).long()\n",
    "    y = torch.ones(1).long()\n",
    "    z = torch.ones(1).long() * 2\n",
    "\n",
    "    ax = torch.index_select(tensor_a, dim, x).squeeze(dim)\n",
    "    ay = torch.index_select(tensor_a, dim, y).squeeze(dim)\n",
    "    az = torch.index_select(tensor_a, dim, z).squeeze(dim)\n",
    "\n",
    "    bx = torch.index_select(tensor_b, dim, x).squeeze(dim)\n",
    "    by = torch.index_select(tensor_b, dim, y).squeeze(dim)\n",
    "    bz = torch.index_select(tensor_b, dim, z).squeeze(dim)\n",
    "\n",
    "    result.append(ay * bz - az * by)\n",
    "    result.append(az * bx - ax * bz)\n",
    "    result.append(ax * by - ay * bx)\n",
    "\n",
    "    result = torch.stack(result, dim=dim)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe786371",
   "metadata": {},
   "source": [
    "### Function to calculate the arc tan between y coordinate and x coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264a0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_atan2(y_coord, x_coord):\n",
    "    eps = 10 ** (-4)\n",
    "    ans = torch.atan(y_coord / (x_coord + eps)) # x > 0\n",
    "    ans = torch.where((y_coord >= 0) & (x_coord < 0), ans + PI_TENSOR, ans)\n",
    "    ans = torch.where((y_coord < 0) & (x_coord < 0), ans - PI_TENSOR, ans)\n",
    "    ans = torch.where((y_coord > 0) & (x_coord == 0), PI_TENSOR / 2, ans)\n",
    "    ans = torch.where((y_coord < 0) & (x_coord == 0), -PI_TENSOR / 2, ans)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc45947",
   "metadata": {},
   "source": [
    "### Function to compute dihedral list from atomic coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e5db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dihedral_list(atomic_coords):\n",
    "    # atomic_coords is -1 x 3\n",
    "    ba = atomic_coords[1:] - atomic_coords[:-1]\n",
    "    ba_normalized = ba / ba.norm(dim=1).unsqueeze(1)\n",
    "    ba_neg = -1 * ba_normalized\n",
    "\n",
    "    n1_vec = compute_cross(ba_normalized[:-2], ba_neg[1:-1], dim=1)\n",
    "    n2_vec = compute_cross(ba_neg[1:-1], ba_normalized[2:], dim=1)\n",
    "\n",
    "    n1_vec_normalized = n1_vec / n1_vec.norm(dim=1).unsqueeze(1)\n",
    "    n2_vec_normalized = n2_vec / n2_vec.norm(dim=1).unsqueeze(1)\n",
    "\n",
    "    m1_vec = compute_cross(n1_vec_normalized, ba_neg[1:-1], dim=1)\n",
    "\n",
    "    x_value = torch.sum(n1_vec_normalized * n2_vec_normalized, dim=1)\n",
    "    y_value = torch.sum(m1_vec * n2_vec_normalized, dim=1)\n",
    "    return compute_atan2(y_value, x_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44842711",
   "metadata": {},
   "source": [
    "### Function to write protein data to a file with atomic and residue chain details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c66b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pdb(file_name, aa_sequence, residue_coords):\n",
    "    residue_names = list([protein_letters_1to3[l].upper() for l in aa_sequence])\n",
    "    num_atoms = len(residue_coords)\n",
    "    backbone_names = num_atoms * [\"N\", \"CA\", \"C\"]\n",
    "\n",
    "    assert num_atoms == len(aa_sequence) * 3\n",
    "    file = open(file_name, 'w')\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        atom_coordinates = list([str(l) for l in np.round(residue_coords[i], 3)])\n",
    "        residue_position = int(i / 3)\n",
    "        atom_id = str(i + 1)\n",
    "        file.write(f\"\"\"\\\n",
    "ATOM  \\\n",
    "{atom_id.rjust(5)} \\\n",
    "{backbone_names[i].rjust(4)} \\\n",
    "{residue_names[residue_position - 1].rjust(3)} \\\n",
    "A\\\n",
    "{str(residue_position).rjust(4)}    \\\n",
    "{atom_coordinates[0].rjust(8)}\\\n",
    "{atom_coordinates[1].rjust(8)}\\\n",
    "{atom_coordinates[2].rjust(8)}\\\n",
    "\\n\"\"\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78635f4b",
   "metadata": {},
   "source": [
    "### Function to use peptidebuilder to get structure from the given angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfde1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_from_angles(aa_list_encoded, angles):\n",
    "    aa_list = protein_id_to_str(aa_list_encoded)\n",
    "    omega_list = angles[1:, 0]\n",
    "    phi_list = angles[1:, 1]\n",
    "    psi_list = angles[:-1, 2]\n",
    "    assert len(aa_list) == len(phi_list) + 1 == len(psi_list) + 1 == len(omega_list) + 1\n",
    "    structure = PeptideBuilder.make_structure(aa_list,\n",
    "                                              list(map(lambda x: math.degrees(x), phi_list)),\n",
    "                                              list(map(lambda x: math.degrees(x), psi_list)),\n",
    "                                              list(map(lambda x: math.degrees(x), omega_list)))\n",
    "    return structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70baf243",
   "metadata": {},
   "source": [
    "### Function to write the protein structure to a PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecc97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_pdb(structure, prot_id):\n",
    "    out = Bio.PDB.PDBIO()\n",
    "    out.set_structure(structure)\n",
    "    out.save(\"output/protein_\" + str(prot_id) + \".pdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d700f",
   "metadata": {},
   "source": [
    "### Function to calculate the distances between two protein chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82be9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pairwise_distances(chain_a, chain_b, use_gpu):\n",
    "    distance_matrix = torch.Tensor(chain_a.size()[0], chain_b.size()[0]).type(torch.float)\n",
    "    # add small epsilon to avoid boundary issues\n",
    "    epsilon = 10 ** (-4) * torch.ones(chain_a.size(0), chain_b.size(0))\n",
    "    if use_gpu:\n",
    "        distance_matrix = distance_matrix.cuda()\n",
    "        epsilon = epsilon.cuda()\n",
    "\n",
    "    for idx, row in enumerate(chain_a.split(1)):\n",
    "        distance_matrix[idx] = torch.sum((row.expand_as(chain_b) - chain_b) ** 2, 1).view(1, -1)\n",
    "\n",
    "    return torch.sqrt(distance_matrix + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251bb55",
   "metadata": {},
   "source": [
    "### Function to calculate Distance Root Mean Square Deviation (DRMSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a330ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pairwise_distances(chain_a, chain_b, use_gpu):\n",
    "    distance_matrix = torch.Tensor(chain_a.size()[0], chain_b.size()[0]).type(torch.float)\n",
    "    # add small epsilon to avoid boundary issues\n",
    "    epsilon = 10 ** (-4) * torch.ones(chain_a.size(0), chain_b.size(0))\n",
    "    if use_gpu:\n",
    "        distance_matrix = distance_matrix.cuda()\n",
    "        epsilon = epsilon.cuda()\n",
    "\n",
    "    for idx, row in enumerate(chain_a.split(1)):\n",
    "        distance_matrix[idx] = torch.sum((row.expand_as(chain_b) - chain_b) ** 2, 1).view(1, -1)\n",
    "\n",
    "    return torch.sqrt(distance_matrix + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043df40",
   "metadata": {},
   "source": [
    "### Function to translate Point Cloud (a set of data points in a 3D coordinate system) into it's center of mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f4d7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_atoms_to_center_of_mass(atoms_matrix):\n",
    "    # calculate com by summing x, y and z respectively\n",
    "    # and dividing by the number of points\n",
    "    center_of_mass = np.matrix([[atoms_matrix[0, :].sum() / atoms_matrix.shape[1]],\n",
    "                                [atoms_matrix[1, :].sum() / atoms_matrix.shape[1]],\n",
    "                                [atoms_matrix[2, :].sum() / atoms_matrix.shape[1]]])\n",
    "    return atoms_matrix - center_of_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b6d03",
   "metadata": {},
   "source": [
    "### Function to calculate Root Mean Square Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmsd(chain_a, chain_b):\n",
    "    # move to center of mass\n",
    "    chain_a_value = chain_a.cpu().numpy().transpose()\n",
    "    chain_b_value = chain_b.cpu().numpy().transpose()\n",
    "    X = transpose_atoms_to_center_of_mass(chain_a_value)\n",
    "    Y = transpose_atoms_to_center_of_mass(chain_b_value)\n",
    "\n",
    "    R = Y * X.transpose()\n",
    "    # extract the singular values\n",
    "    _, S, _ = np.linalg.svd(R)\n",
    "    # compute RMSD using the formular\n",
    "    E0 = sum(list(np.linalg.norm(x) ** 2 for x in X.transpose())\n",
    "             + list(np.linalg.norm(x) ** 2 for x in Y.transpose()))\n",
    "    TraceS = sum(S)\n",
    "    RMSD = np.sqrt((1 / len(X.transpose())) * (E0 - 2 * TraceS))\n",
    "    return RMSD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef0355",
   "metadata": {},
   "source": [
    "### Function to calculate angular differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a6a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angular_difference(values_1, values_2):\n",
    "    values_1 = values_1.transpose(0, 1).contiguous()\n",
    "    values_2 = values_2.transpose(0, 1).contiguous()\n",
    "    acc = 0\n",
    "    for idx, _ in enumerate(values_1):\n",
    "        assert values_1[idx].shape[1] == 3\n",
    "        assert values_2[idx].shape[1] == 3\n",
    "        a1_element = values_1[idx].view(-1, 1)\n",
    "        a2_element = values_2[idx].view(-1, 1)\n",
    "        acc += torch.sqrt(torch.mean(\n",
    "            torch.min(torch.abs(a2_element - a1_element),\n",
    "                      2 * math.pi - torch.abs(a2_element - a1_element)\n",
    "                      ) ** 2))\n",
    "    return acc / values_1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c683e1d",
   "metadata": {},
   "source": [
    "### Fucntion to convert the given structures into the backbone atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b510fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_to_backbone_atoms(structure):\n",
    "    predicted_coords = []\n",
    "    for res in structure.get_residues():\n",
    "        predicted_coords.append(torch.Tensor(res[\"N\"].get_coord()))\n",
    "        predicted_coords.append(torch.Tensor(res[\"CA\"].get_coord()))\n",
    "        predicted_coords.append(torch.Tensor(res[\"C\"].get_coord()))\n",
    "    return torch.stack(predicted_coords).view(-1, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccb4dc",
   "metadata": {},
   "source": [
    "### Function to add padding to the backbone atoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9246a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structures_to_backbone_atoms_padded(structures):\n",
    "    backbone_atoms_list = []\n",
    "    for structure in structures:\n",
    "        backbone_atoms_list.append(structure_to_backbone_atoms(structure))\n",
    "    backbone_atoms_padded, batch_sizes_backbone = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "        torch.nn.utils.rnn.pack_sequence(backbone_atoms_list))\n",
    "    return backbone_atoms_padded, batch_sizes_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23b7f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAGMENTS = torch.tensor(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ef9eb",
   "metadata": {},
   "source": [
    "### Function to get the backbone atom positions from the angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25a3a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_positions_from_angles(angular_emissions, batch_sizes, use_gpu):\n",
    "    # angular_emissions -1 x minibatch size x 3 (omega, phi, psi)\n",
    "    points = dihedral_to_point(angular_emissions, use_gpu)\n",
    "    coordinates = point_to_coordinate(\n",
    "        points,\n",
    "        use_gpu,\n",
    "        num_fragments=NUM_FRAGMENTS) / 100  # divide by 100 to angstrom unit\n",
    "    return coordinates.transpose(0, 1).contiguous()\\\n",
    "               .view(len(batch_sizes), -1, 9).transpose(0, 1), batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff17b11",
   "metadata": {},
   "source": [
    "### Function to calculate average DRMSD for the mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a69a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_drmsd_over_minibatch(backbone_atoms_padded, actual_coords_padded, batch_sizes):\n",
    "    backbone_atoms_list = list(\n",
    "        [backbone_atoms_padded[:batch_sizes[i], i] for i in range(int(backbone_atoms_padded\n",
    "                                                                      .size(1)))])\n",
    "    actual_coords_list = list(\n",
    "        [actual_coords_padded[:batch_sizes[i], i] for i in range(int(actual_coords_padded\n",
    "                                                                     .size(1)))])\n",
    "    drmsd_avg = 0\n",
    "    for idx, backbone_atoms in enumerate(backbone_atoms_list):\n",
    "        actual_coords = actual_coords_list[idx].transpose(0, 1).contiguous().view(-1, 3)\n",
    "        drmsd_avg += calc_drmsd(backbone_atoms.transpose(0, 1).contiguous().view(-1, 3),\n",
    "                                actual_coords)\n",
    "    return drmsd_avg / len(backbone_atoms_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df9384",
   "metadata": {},
   "source": [
    "### Function to return the Amino Acids for the primary string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3909596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_primary_string(primary):\n",
    "    return list([AA_ID_DICT[aa] for aa in primary])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e4e7f",
   "metadata": {},
   "source": [
    "### Function to get the initial positions from of the atoms from the AA String of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8108708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_pos_from_aa_string(batch_aa_string, use_gpu):\n",
    "    arr_of_angles = []\n",
    "    batch_sizes = []\n",
    "    for aa_string in batch_aa_string:\n",
    "        length_of_protein = aa_string.size(0)\n",
    "        angles = torch.stack([-120*torch.ones(length_of_protein),\n",
    "                              140*torch.ones(length_of_protein),\n",
    "                              -370*torch.ones(length_of_protein)]).transpose(0, 1)\n",
    "        arr_of_angles.append(angles)\n",
    "        batch_sizes.append(length_of_protein)\n",
    "\n",
    "    padded = pad_sequence(arr_of_angles).transpose(0, 1)\n",
    "    return get_backbone_positions_from_angles(padded, batch_sizes, use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc1b78",
   "metadata": {},
   "source": [
    "### Function to convert dihedral angles to a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a0fbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dihedral_to_point(dihedral, use_gpu, bond_lengths=BOND_LENGTHS,\n",
    "                      bond_angles=BOND_ANGLES):\n",
    "    num_steps = dihedral.shape[0]\n",
    "    batch_size = dihedral.shape[1]\n",
    "\n",
    "    r_cos_theta = bond_lengths * torch.cos(PI_TENSOR - bond_angles)\n",
    "    r_sin_theta = bond_lengths * torch.sin(PI_TENSOR - bond_angles)\n",
    "\n",
    "    if use_gpu:\n",
    "        r_cos_theta = r_cos_theta.cuda()\n",
    "        r_sin_theta = r_sin_theta.cuda()\n",
    "\n",
    "    point_x = r_cos_theta.view(1, 1, -1).repeat(num_steps, batch_size, 1)\n",
    "    point_y = torch.cos(dihedral) * r_sin_theta\n",
    "    point_z = torch.sin(dihedral) * r_sin_theta\n",
    "\n",
    "    point = torch.stack([point_x, point_y, point_z])\n",
    "    point_perm = point.permute(1, 3, 2, 0)\n",
    "    point_final = point_perm.contiguous().view(num_steps * NUM_DIHEDRALS,\n",
    "                                               batch_size,\n",
    "                                               NUM_DIMENSIONS)\n",
    "    return point_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b45c8",
   "metadata": {},
   "source": [
    "### Function to convert a point from the dihedral conversions into coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4037cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_coordinate(points, use_gpu, num_fragments):\n",
    "    total_num_angles = points.size(0) \n",
    "    if isinstance(total_num_angles, int):\n",
    "        total_num_angles = torch.tensor(total_num_angles)\n",
    "\n",
    "    Triplet = collections.namedtuple('Triplet', 'a, b, c')\n",
    "    batch_size = points.shape[1]\n",
    "\n",
    "    init_coords = []\n",
    "    for row in PNERF_INIT_MATRIX:\n",
    "        row_tensor = row\\\n",
    "                .repeat([num_fragments * batch_size, 1])\\\n",
    "                .view(num_fragments, batch_size, NUM_DIMENSIONS)\n",
    "        if use_gpu:\n",
    "            row_tensor = row_tensor.cuda()\n",
    "        init_coords.append(row_tensor)\n",
    "\n",
    "    init_coords = Triplet(*init_coords) \n",
    "    padding = torch.fmod(num_fragments - (total_num_angles % num_fragments), num_fragments)\n",
    "    padding_tensor = torch.zeros((padding, points.size(1), points.size(2)))\n",
    "    points = torch.cat((points, padding_tensor))\n",
    "\n",
    "    points = points.view(num_fragments, -1, batch_size,\n",
    "                         NUM_DIMENSIONS)\n",
    "    points = points.permute(1, 0, 2, 3)\n",
    "\n",
    "    def extend(prev_three_coords, point, multi_m):\n",
    "        bc = F.normalize(prev_three_coords.c - prev_three_coords.b, dim=-1)\n",
    "        n = F.normalize(compute_cross(prev_three_coords.b - prev_three_coords.a,\n",
    "                                      bc, dim=2 if multi_m else 1), dim=-1)\n",
    "        if multi_m:  # multiple fragments, one atom at a time\n",
    "            m = torch.stack([bc, compute_cross(n, bc, dim=2), n]).permute(1, 2, 3, 0)\n",
    "        else:  # single fragment, reconstructed entirely at once.\n",
    "            s = point.shape + (3,)\n",
    "            m = torch.stack([bc, compute_cross(n, bc, dim=1), n]).permute(1, 2, 0)\n",
    "            m = m.repeat(s[0], 1, 1).view(s)\n",
    "        coord = torch.squeeze(torch.matmul(m, point.unsqueeze(3)),\n",
    "                              dim=3) + prev_three_coords.c\n",
    "        return coord\n",
    "\n",
    "    coords_list = []\n",
    "    prev_three_coords = init_coords\n",
    "\n",
    "    for point in points.split(1, dim=0):  # Iterate over FRAG_SIZE\n",
    "        coord = extend(prev_three_coords, point.squeeze(0), True)\n",
    "        coords_list.append(coord)\n",
    "        prev_three_coords = Triplet(prev_three_coords.b,\n",
    "                                    prev_three_coords.c,\n",
    "                                    coord)\n",
    "\n",
    "    coords_pretrans = torch.stack(coords_list).permute(1, 0, 2, 3)\n",
    "    coords_trans = coords_pretrans[-1]\n",
    "    for idx in torch.arange(end=-1, start=coords_pretrans.shape[0] - 2, step=-1).split(1, dim=0):\n",
    "        transformed_coords = extend(Triplet(*[di.index_select(0, idx).squeeze(0)\n",
    "                                              for di in prev_three_coords]),\n",
    "                                    coords_trans, False)\n",
    "        coords_trans = torch.cat(\n",
    "            [coords_pretrans.index_select(0, idx).squeeze(0), transformed_coords], 0)\n",
    "\n",
    "    coords_to_pad = torch.index_select(coords_trans, 0, torch.arange(total_num_angles - 1))\n",
    "\n",
    "    coords = F.pad(coords_to_pad, (0, 0, 0, 0, 1, 0))\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a742f9c",
   "metadata": {},
   "source": [
    "### Function to load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3df6accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_disk(path, force_cpu=True):\n",
    "    if force_cpu:\n",
    "        model = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        model.flatten_parameters()\n",
    "        model.use_gpu = False\n",
    "    else:\n",
    "        model = torch.load(path)\n",
    "        model.flatten_parameters()\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
